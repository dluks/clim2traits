{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Explore results\n",
    "Author: Daniel Lusk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import dask_geopandas as dgpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray as riox\n",
    "import seaborn as sns\n",
    "\n",
    "from geocube.api.core import make_geocube\n",
    "\n",
    "\n",
    "from utils.geodata import compare_grids, compare_gdf_to_grid, pad_ds\n",
    "from utils.geodata import read_001_predictions, splot_correlation_old\n",
    "\n",
    "from utils.visualize import plot_all_trait_obs_pred, plot_pred_cov\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the results, map trait IDs to trait names, and remove unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"results/training_results.csv\")\n",
    "\n",
    "# Rename response variable values according to the trait id -> trait name mapping\n",
    "with open(\"./trait_id_to_trait_name.json\", \"r\") as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "# Create a new column called \"Trait name\" according to the pattern \"TRYgapfilled_X{trait_id}_\" with {trait_name}\n",
    "for trait_id, trait in mapping.items():\n",
    "    results.loc[results[\"Response variable\"].str.contains(trait_id), \"Trait name\"] = trait\n",
    "\n",
    "# Rename \"Test r-squared\" to \"Full r-squared\"\n",
    "results = results.rename(columns={\"Test r-squared\": \"Full r-squared\"})\n",
    "\n",
    "run_id_mapping = {\n",
    "    \"2023-09-23_11-44-08\": \"Original\",\n",
    "    \"2023-09-23_12-39-35\": \"Original + Imputed\",\n",
    "    \"2023-09-23_13-30-09\": \"Log-transformed\",\n",
    "    \"2023-09-23_14-19-41\": \"Log + Imputed\",\n",
    "}\n",
    "\n",
    "# Only select four most recent run IDs\n",
    "results = results[results[\"Run ID\"].isin(run_id_mapping.keys())]\n",
    "\n",
    "# Add new column \"Run type\" which maps each run ID to its corresponding run type\n",
    "results[\"Run type\"] = results[\"Run ID\"].map(run_id_mapping)\n",
    "\n",
    "# Isolate \"Predictor importance\" into its own dataframe (still retaining Run ID and Response variable)\n",
    "PI = results[[\"Run ID\", \"Run type\", \"Response variable\", \"Trait name\", \"Predictor importance\", \"CV predictor importance\"]]\n",
    "\n",
    "results = results[\n",
    "    [\n",
    "        \"Run ID\",\n",
    "        \"Run type\",\n",
    "        \"Response variable\",\n",
    "        \"Trait name\",\n",
    "        \"N observations\",\n",
    "        \"CV nRMSE\",\n",
    "        \"CV nRMSE STD\",\n",
    "        \"CV r-squared\",\n",
    "        \"CV r-squared STD\",\n",
    "        \"Full r-squared\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the top ten and bottom ten models from overall results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=[\"CV r-squared\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=[\"CV r-squared\"], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some quick takeaways:**\n",
    "- the sPlot traits resulted in the best models. This is likely due to its smaller sample size and (likely) reduced variance.\n",
    "- It appears that log-transforming the trait data resulted in models that were unable to be fit to the corresponding predictor variables.\n",
    "\n",
    "Let's set a CV R^2 threshold of 0.05 to remove these outliers and explore the overall performance of each training suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[results[\"CV r-squared\"] > 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot overall results CV r-squared as box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2)\n",
    "axs = axs.flatten()\n",
    "\n",
    "models = [\"Original\", \"Original + Imputed\", \"Log-transformed\", \"Log + Imputed\"]\n",
    "metrics = [\"CV r-squared\", \"CV r-squared STD\", \"CV nRMSE\", \"Full r-squared\"]\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    for j, model in enumerate(models):\n",
    "        ax = axs[i]\n",
    "        sns.boxplot(x=\"Run type\", y=metric, data=results, order=models, ax=ax)\n",
    "        # data = results[results[\"Run ID\"] == model][metric]\n",
    "        # sns.boxplot(data=data, ax=ax)\n",
    "        ax.set(xlabel=\"Data treatment\", label=metric)\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontweight='bold')\n",
    "        ax.set_ylabel(ax.get_ylabel(), fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping outlier models from the log-transformed suite of models, the log-transformed models appear to perform best in terms of CV R^2 and Overall R^2 and with a generally lower CV nRMSE, but greater variance in its CV R^2 standard deviation. This makes sense, as many of the untransformed traits were already normally distributed, and so log-transforming them would likley result in poorer model fitting.\n",
    "\n",
    "In general, it appears that there is not a big difference between predictor datasets with missing values and imputed datasets, though the CV R^2 STD does increase slightly for models trained on non-imputed datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's isolate the best performing models for each trait**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First filter out rows that contain \"imputed\" in the Run ID column\n",
    "results_mvs = results[~results[\"Run type\"].str.contains(\"Imputed\")]\n",
    "\n",
    "# Next split results into GBIF and sPlot dataframes\n",
    "results_gbif = results_mvs[results_mvs[\"Response variable\"].str.contains(\"GBIF\")]\n",
    "results_splot = results_mvs[results_mvs[\"Response variable\"].str.contains(\"sPlot\")]\n",
    "\n",
    "# Next create empty dataframes (one for GBIF and one for sPlot) with the same column names as the results dataframe\n",
    "# Then, for each trait, get the row with the highest CV r-squared and append it to the empty dataframe\n",
    "# This will give us the best model for each trait\n",
    "\n",
    "best_models_gbif = pd.DataFrame(\n",
    "    columns=results_gbif.columns.values,\n",
    "    # index=range(len(mapping)),\n",
    ")\n",
    "best_models_splot = pd.DataFrame(\n",
    "    columns=results_splot.columns.values,\n",
    "    # index=range(len(mapping)),\n",
    ")\n",
    "\n",
    "for i, (_, trait) in enumerate(mapping.items()):\n",
    "    best_gbif_row = (\n",
    "        results_gbif[results_gbif[\"Trait name\"].str.contains(trait, regex=False)]\n",
    "        .sort_values(by=[\"CV r-squared\"], ascending=False)\n",
    "        .iloc[0]\n",
    "    )\n",
    "    best_models_gbif = pd.concat([best_models_gbif, best_gbif_row.to_frame().T])\n",
    "    \n",
    "    # The best GBIF run types don't necessarily correspond to the best sPlot run types\n",
    "    # for the same traits, but for an apples-to-apples comparison we should use the same\n",
    "    # run types for both datasets\n",
    "    best_gbif_trait = best_gbif_row[\"Response variable\"].split(\"GBIF_\")[1]\n",
    "\n",
    "    best_splot_row = (\n",
    "        results_splot[\n",
    "            results_splot[\"Response variable\"].str.contains(best_gbif_trait)\n",
    "        ]\n",
    "        .sort_values(by=[\"CV r-squared\"], ascending=False)\n",
    "        .iloc[0]\n",
    "    )\n",
    "\n",
    "    best_models_splot = pd.concat([best_models_splot, best_splot_row.to_frame().T])\n",
    "\n",
    "best_models_gbif = best_models_gbif.sort_values(by=[\"CV r-squared\"], ascending=False)\n",
    "best_models_splot = best_models_splot.sort_values(by=[\"CV r-squared\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_gbif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_models_gbif.to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_models_splot.to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure with scatterplots of CV-predictions vs observed for each of a subset of traits, along with R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(\"results/training\")\n",
    "# Create a list of tuples of Run ID and Response variable for each row in best_models_gbif and best_models_splot\n",
    "# This will be used to filter out the results dataframes to only include the best model for each trait\n",
    "gbif_id_rvs = list(\n",
    "    zip(best_models_gbif[\"Run ID\"], best_models_gbif[\"Response variable\"])\n",
    ")\n",
    "splot_id_rvs = list(\n",
    "    zip(best_models_splot[\"Run ID\"], best_models_splot[\"Response variable\"])\n",
    ")\n",
    "\n",
    "gbif_trait_dirs = [Path(results_dir / run_id / rv) for run_id, rv in gbif_id_rvs]\n",
    "splot_trait_dirs = [Path(results_dir / run_id / rv) for run_id, rv in splot_id_rvs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_trait_obs_pred(gbif_trait_dirs, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_trait_obs_pred(splot_trait_dirs, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crowd-sourced vs sPlotOpen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: Box plot of GBIF and sPlot CV-R2 (y-axis) for each trait (x-axis). I.e. two boxes for each trait, one for GBIF and one for sPlot. Could print RMSE ± STD for each one, too?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_gbif = best_models_gbif.sort_values(by=[\"CV r-squared\"], ascending=False)\n",
    "best_models_splot = best_models_splot.sort_values(by=[\"CV r-squared\"], ascending=False)\n",
    "\n",
    "# For each matching Response variable in best_models_gbif and best_models_splot, plot\n",
    "# the CV r-squared values as a bar chart, with the corresponding CV r-squared STD representing the error bars\n",
    "\n",
    "# First, drop the GBIF_ and sPlot_ prefixes from the Response variable column\n",
    "best_models_gbif[\"Response variable\"] = best_models_gbif[\"Response variable\"].str.replace(\"GBIF_\", \"\")\n",
    "best_models_splot[\"Response variable\"] = best_models_splot[\"Response variable\"].str.replace(\"sPlot_\", \"\")\n",
    "\n",
    "# Then, merge the two dataframes on Response variable\n",
    "best_models_gbif_splot = pd.merge(best_models_gbif, best_models_splot, on=\"Response variable\", suffixes=(\"_gbif\", \"_splot\"))\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the plot style\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# set the figure size\n",
    "plt.figure(figsize=(25, 9))\n",
    "\n",
    "# set the x-axis labels\n",
    "x_labels = best_models_gbif_splot[\"Trait name_gbif\"]\n",
    "\n",
    "# set the bar width\n",
    "bar_width = 0.35\n",
    "\n",
    "# set the x-axis positions\n",
    "x_pos = [i for i in range(len(x_labels))]\n",
    "\n",
    "# plot the GBIF CV r-squared values as bars\n",
    "gbif_r2 = best_models_gbif_splot[\"CV r-squared_gbif\"]\n",
    "gbif_std = best_models_gbif_splot[\"CV r-squared STD_gbif\"]\n",
    "plt.bar(x_pos, gbif_r2, width=bar_width, yerr=gbif_std, label=\"GBIF\")\n",
    "\n",
    "# plot the sPlot CV r-squared values as bars\n",
    "splot_r2 = best_models_gbif_splot[\"CV r-squared_splot\"]\n",
    "splot_std = best_models_gbif_splot[\"CV r-squared STD_splot\"]\n",
    "plt.bar([i + bar_width for i in x_pos], splot_r2, width=bar_width, yerr=splot_std, label=\"sPlot\")\n",
    "\n",
    "# set the x-axis labels and title\n",
    "plt.xlabel(\"Response variable\")\n",
    "# Y label as \"CV R2\" with the 2 in R2 in superscript\n",
    "plt.ylabel(\"CV R$^2$\")\n",
    "# plt.title(\"CV R$^2$ values for GBIF and sPlot\")\n",
    "\n",
    "# set the x-axis tick positions and labels\n",
    "plt.xticks([i + bar_width / 2 for i in x_pos], x_labels, rotation=90)\n",
    "\n",
    "# add a legend\n",
    "plt.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table (or bar chart) showing global cover % for GBIF vs sPlotOpen traits (should include CV R2 for each model, too, since GBIF generally has lower R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_name = \"MOD09GA.061_ISRIC_soil_WC_BIO_VODCA_0.5_deg_nan-strat=any_thr=0.5\"\n",
    "predicted_traits = list(Path(f\"results/predictions/{predict_name}/\").glob(\"*\"))\n",
    "# select_traits = [trait.name for trait in select_traits]\n",
    "\n",
    "# replace trait id with trait name from mapping\n",
    "# for i, trait in enumerate(select_traits):\n",
    "#     trait_id = trait.split(\"_\")[1].split(\"X\")[-1]\n",
    "#     trait_name = mapping[trait_id]\n",
    "#     select_traits[i] = trait.replace(f\"X{trait_id}\", trait_name)\n",
    "\n",
    "aoa_df = pd.DataFrame(\n",
    "    columns=[\"Response variable\", \"GBIF AOA\", \"sPlot AOA\", \"Pct change\"],\n",
    "    index=range(len(predicted_traits)),\n",
    ")\n",
    "\n",
    "gbif_predictions = []\n",
    "splot_predictions = []\n",
    "\n",
    "for i, trait in enumerate(predicted_traits):\n",
    "    if not trait.is_dir():\n",
    "        continue\n",
    "    gbif_trait_df = gpd.read_parquet(trait / f\"GBIF/{predict_name}_predict.parq\")\n",
    "    splot_trait_df = gpd.read_parquet(trait / f\"sPlot/{predict_name}_predict.parq\")\n",
    "\n",
    "    gbif_predictions.append(gbif_trait_df)\n",
    "    splot_predictions.append(splot_trait_df)\n",
    "    \n",
    "    # For each trait, add a new row to aoa_df with the response variable, GBIF AOA, and sPlot AOA\n",
    "\n",
    "    gbif_aoa = gbif_trait_df[\"AOA\"].sum() / gbif_trait_df[\"AOA\"].count()\n",
    "    splot_aoa = splot_trait_df[\"AOA\"].sum() / splot_trait_df[\"AOA\"].count()\n",
    "\n",
    "    # map trait id to trait name\n",
    "    trait_id = trait.name.split(\"_\")[1].split(\"X\")[-1]\n",
    "    trait_name = mapping[trait_id]\n",
    "\n",
    "    new_row = {\n",
    "        \"Response variable\": trait_name,\n",
    "        \"GBIF AOA\": gbif_aoa,\n",
    "        \"sPlot AOA\": splot_aoa,\n",
    "        \"Pct change\": (gbif_aoa - splot_aoa) * 100,\n",
    "    }\n",
    "\n",
    "    aoa_df.iloc[i] = new_row\n",
    "\n",
    "aoa_df = aoa_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aoa_df.to_markdown(index=False, floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_df[\"Pct change\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global trait maps visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure of global trait maps for selected traits with two columns—left column containing trait predictions masked by AoA, right column containing trait prediction CoV (also masked by AoA?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, back-transform trait values predicted by models trained in log-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (gbif, splot) in enumerate(zip(gbif_predictions, splot_predictions)):\n",
    "    if gbif.columns[0].endswith(\"_ln\"):\n",
    "        # back-transform columns 0 and 4\n",
    "        gbif.iloc[:, 0] = np.exp(gbif.iloc[:, 0])\n",
    "        gbif.iloc[:, 4] = np.exp(gbif.iloc[:, 4])\n",
    "    \n",
    "    if splot.columns[0].endswith(\"_ln\"):\n",
    "        # back-transform columns 0 and 4\n",
    "        splot.iloc[:, 0] = np.exp(splot.iloc[:, 0])\n",
    "        splot.iloc[:, 4] = np.exp(splot.iloc[:, 4])\n",
    "    \n",
    "    # rename columns 0 and 4 by replacing \"_ln\" with nothing\n",
    "    gbif = gbif.rename(columns={gbif.columns[0]: gbif.columns[0].replace(\"_ln\", \"\")})\n",
    "    gbif = gbif.rename(columns={gbif.columns[4]: gbif.columns[4].replace(\"_ln\", \"\")})\n",
    "\n",
    "    splot = splot.rename(columns={splot.columns[0]: splot.columns[0].replace(\"_ln\", \"\")})\n",
    "    splot = splot.rename(columns={splot.columns[4]: splot.columns[4].replace(\"_ln\", \"\")})\n",
    "\n",
    "    gbif_predictions[i] = gbif\n",
    "    splot_predictions[i] = splot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (gbif, splot) in enumerate(zip(gbif_predictions, splot_predictions)):\n",
    "    gbif_predictions[i] = make_geocube(vector_data=gbif, resolution=(-0.5, 0.5))\n",
    "    gbif_predictions[i] = pad_ds(gbif_predictions[i])\n",
    "\n",
    "    splot_predictions[i] = make_geocube(vector_data=splot, resolution=(-0.5, 0.5))\n",
    "    splot_predictions[i] = pad_ds(splot_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_cov(gbif_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure (appendix): All remaining global trait maps with > R2-THRESHOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter models with a CV r^2 below 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_gbif = PI.loc[best_models_gbif[best_models_gbif[\"CV r-squared\"] > 0.2].index]\n",
    "pi_splot = PI.loc[best_models_splot[best_models_splot[\"CV r-squared\"] > 0.2].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_importance(PIs):\n",
    "    \n",
    "    PIs = ast.literal_eval(PIs)\n",
    "\n",
    "    ds_keys = {\n",
    "        \"MODIS\": [\"sur_refl\"],\n",
    "        \"WorldClim\": [\"wc2.1\"],\n",
    "        \"Soil\": [\"0-5cm\", \"0-30cm\", \"5-15cm\", \"15-30cm\", \"30-60cm\", \"60-100cm\", \"100-200cm\"],\n",
    "        \"VODCA\": [\"C_2\", \"Ku_2\", \"X_2\"]\n",
    "    }\n",
    "\n",
    "    # Get the average and standard deviation of the predictor importance values for each dataset\n",
    "    PIs = {\n",
    "        k: [np.mean(v), np.std(v)] for k, v in PIs.items()\n",
    "    }\n",
    "\n",
    "    ds_importance = {}\n",
    "\n",
    "    for ds, keys in ds_keys.items():\n",
    "        \n",
    "        for feature, imp in PIs.items():\n",
    "            for key in keys:\n",
    "                if key in feature:\n",
    "                    if ds not in ds_importance:\n",
    "                        ds_importance[ds] = []\n",
    "                    ds_importance[ds].append(imp)\n",
    "    \n",
    "    return ds_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DS importance for each response variable in PI_orig_gbif and PI_orig_splot\n",
    "pi_gbif[\"DS importance\"] = pi_gbif[\"CV predictor importance\"].apply(ds_importance)\n",
    "pi_splot[\"DS importance\"] = pi_splot[\"CV predictor importance\"].apply(ds_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: box and whisker plot of predictor datasets (x-axis) and their average importances across all traits for which models had a > R2-THRESHOLD score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of dataframes for each dataset for GBIF\n",
    "dfs_gbif = []\n",
    "for ds in pi_gbif[\"DS importance\"].iloc[0].keys():\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Dataset\": ds,\n",
    "            \"Mean importance\": [\n",
    "                np.asarray(imp[ds])[:, 0].mean() for imp in pi_gbif[\"DS importance\"]\n",
    "            ],\n",
    "            \"STD importance\": [\n",
    "                np.asarray(imp[ds])[:, 1].mean() for imp in pi_gbif[\"DS importance\"]\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    dfs_gbif.append(df)\n",
    "\n",
    "# concatenate the dataframes into a single dataframe for GBIF\n",
    "df_gbif = pd.concat(dfs_gbif)\n",
    "\n",
    "# create a list of dataframes for each dataset for sPlot\n",
    "dfs_splot = []\n",
    "for ds in pi_splot[\"DS importance\"].iloc[0].keys():\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Dataset\": ds,\n",
    "            \"Mean importance\": [\n",
    "                np.asarray(imp[ds])[:, 0].mean() for imp in pi_splot[\"DS importance\"]\n",
    "            ],\n",
    "            \"STD importance\": [\n",
    "                np.asarray(imp[ds])[:, 1].mean() for imp in pi_splot[\"DS importance\"]\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    dfs_splot.append(df)\n",
    "\n",
    "# concatenate the dataframes into a single dataframe for sPlot\n",
    "df_splot = pd.concat(dfs_splot)\n",
    "\n",
    "# set the plot style\n",
    "sns.set_theme()\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# create the figure and subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# plot the GBIF boxplot\n",
    "sns.boxplot(x=\"Dataset\", y=\"Mean importance\", data=df_gbif, ax=axs[0])\n",
    "axs[0].set_xlabel(\"Dataset\")\n",
    "axs[0].set_ylabel(\"Mean importance\")\n",
    "axs[0].set_title(\"Predictor dataset importances for GBIF\\nmodels with >0.2 CV r-squared\")\n",
    "\n",
    "# plot the sPlot boxplot\n",
    "sns.boxplot(x=\"Dataset\", y=\"Mean importance\", data=df_splot, ax=axs[1])\n",
    "axs[1].set_xlabel(\"Dataset\")\n",
    "axs[1].set_ylabel(\"\")\n",
    "axs[1].set_title(\"Predictor dataset importances for sPlot\\nmodels with >0.2 CV r-squared\")\n",
    "\n",
    "# adjust the layout and spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure (appendix): Feature importance of individual predictors across all traits for which models had a > R2-THRESHOLD score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of GBIF (and other products) with sPlotOpen grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 degree grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other products (0.5 degree)\n",
    "product_dir = Path(\"data/other-products/all-prods_stacks_sla-nit-nita_05D_2022-02-14\")\n",
    "N_mass = riox.open_rasterio(product_dir / \"all-prods_nit_stack_all-maps_05D_2022-02-14.grd\", masked=True)\n",
    "N_area = riox.open_rasterio(product_dir / \"all-prods_nita_stack_all-maps_05D_2022-02-14.grd\", masked=True)\n",
    "SLA  = riox.open_rasterio(product_dir / \"all-prods_sla_stack_all-maps_05D_2022-02-14.grd\", masked=True)\n",
    "\n",
    "# Extrapolations\n",
    "pred_05_dir = Path(\"results/predictions/05deg_models/MOD09GA.061_ISRIC_soil_WC_BIO_VODCA_0.5_deg_nan-strat=any_thr=0.5\", \"Shrub_Tree_Grass\")\n",
    "pred_05_fn = \"MOD09GA.061_ISRIC_soil_WC_BIO_VODCA_0.5_deg_nan-strat=any_thr=0.5_predict.parq\"\n",
    "\n",
    "# GBIF extrapolations (0.5 degree)\n",
    "gbif_N_mass_05 = gpd.read_parquet(pred_05_dir / \"TRYgapfilled_X14_05deg_mean/GBIF\" / pred_05_fn)\n",
    "gbif_N_area_05 = gpd.read_parquet(pred_05_dir / \"TRYgapfilled_X50_05deg_mean_ln/GBIF\" / pred_05_fn)\n",
    "gbif_SLA_05 = gpd.read_parquet(pred_05_dir / \"TRYgapfilled_X11_05deg_mean/GBIF\" / pred_05_fn)\n",
    "\n",
    "# sPlot extrapolations (0.5 degree)\n",
    "sPlot_ext_N_mass_05 = gpd.read_parquet(pred_05_dir / \"TRYgapfilled_X14_05deg_mean/sPlot\" / pred_05_fn)\n",
    "sPlot_ext_N_area_05 = gpd.read_parquet(pred_05_dir / \"TRYgapfilled_X50_05deg_mean_ln/sPlot\" / pred_05_fn)\n",
    "sPlot_ext_SLA_05 = gpd.read_parquet(pred_05_dir / \"TRYgapfilled_X11_05deg_mean/sPlot\" / pred_05_fn)\n",
    "\n",
    "# sPlot maps (0.5 degree)\n",
    "sPlot_N_mass_05 = riox.open_rasterio(\"./GBIF_trait_maps/global_maps/Shrub_Tree_Grass/05deg/sPlot_TRYgapfilled_X14_05deg.grd\", masked=True).sel(band=2)\n",
    "sPlot_N_area_05 = riox.open_rasterio(\"./GBIF_trait_maps/global_maps/Shrub_Tree_Grass/05deg/sPlot_TRYgapfilled_X50_05deg.grd\", masked=True).sel(band=2)\n",
    "sPlot_SLA_05 = riox.open_rasterio(\"./GBIF_trait_maps/global_maps/Shrub_Tree_Grass/05deg/sPlot_TRYgapfilled_X11_05deg.grd\", masked=True).sel(band=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back-transform `gbif_N_area` and `sPlot_N_area` as they were trained on log-transformed trait values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back-transform `gbif_N_area` as it was trained on log-transformed trait values\n",
    "gbif_N_area_05[\"GBIF_TRYgapfilled_X50_05deg_mean\"] = np.exp(gbif_N_area_05[\"GBIF_TRYgapfilled_X50_05deg_mean_ln\"])\n",
    "sPlot_ext_N_area_05[\"sPlot_TRYgapfilled_X50_05deg_mean\"] = np.exp(sPlot_ext_N_area_05[\"sPlot_TRYgapfilled_X50_05deg_mean_ln\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_table = pd.DataFrame(columns=[\"Leaf N mass\"])\n",
    "\n",
    "splot_corr = compare_gdf_to_grid(sPlot_ext_N_mass_05, sPlot_N_mass_05, \"sPlot_TRYgapfilled_X14_05deg_mean\", \"sPlot_N_mass\")\n",
    "gbif_corr = compare_gdf_to_grid(gbif_N_mass_05, sPlot_N_mass_05, \"GBIF_TRYgapfilled_X14_05deg_mean\", \"sPlot_N_mass\")\n",
    "\n",
    "corr_table = pd.concat([corr_table, pd.DataFrame([splot_corr, gbif_corr], columns=[\"Leaf N mass\"], index=[\"sPlot (extrap.)\", \"GBIF\"])])\n",
    "\n",
    "for i, band in enumerate(N_mass):\n",
    "    band_name = band.long_name[i]\n",
    "    corr = compare_grids(band, sPlot_N_mass_05, band_name, \"sPlot_N_mass\")\n",
    "    corr_table = pd.concat([corr_table, pd.DataFrame([corr], columns=[\"Leaf N mass\"], index=[band_name])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splot_corr = compare_gdf_to_grid(sPlot_ext_N_area_05, sPlot_N_area_05, \"sPlot_TRYgapfilled_X50_05deg_mean\", \"sPlot_N_area\")\n",
    "gbif_corr = compare_gdf_to_grid(gbif_N_area_05, sPlot_N_area_05, \"GBIF_TRYgapfilled_X50_05deg_mean\", \"sPlot_N_area\")\n",
    "\n",
    "corr_table.loc[\"GBIF\", \"Leaf N area\"] = gbif_corr\n",
    "corr_table.loc[\"sPlot (extrap.)\", \"Leaf N area\"] = splot_corr\n",
    "\n",
    "for i, band in enumerate(N_area):\n",
    "    band_name = band.long_name[i]\n",
    "    corr = compare_grids(band, sPlot_N_area_05, band_name, \"sPlot_N_area\")\n",
    "    if band_name in corr_table.index:\n",
    "        corr_table.loc[band_name, \"Leaf N area\"] = corr\n",
    "    else:\n",
    "        corr_table = pd.concat([corr_table, pd.DataFrame({\"Leaf N area\": corr}, index=[band_name])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splot_corr = compare_gdf_to_grid(sPlot_ext_SLA_05, sPlot_SLA_05, \"sPlot_TRYgapfilled_X11_05deg_mean\", \"sPlot_SLA\")\n",
    "gbif_corr = compare_gdf_to_grid(gbif_SLA_05, sPlot_SLA_05, \"GBIF_TRYgapfilled_X11_05deg_mean\", \"sPlot_SLA\")\n",
    "\n",
    "corr_table.loc[\"GBIF\", \"Leaf SLA\"] = gbif_corr\n",
    "corr_table.loc[\"sPlot (extrap.)\", \"Leaf SLA\"] = splot_corr\n",
    "\n",
    "for i, band in enumerate(SLA):\n",
    "    band_name = band.long_name[i]\n",
    "    corr = compare_grids(band, sPlot_SLA_05, band_name, \"sPlot_SLA\")\n",
    "    if band_name in corr_table.index:\n",
    "        corr_table.loc[band_name, \"Leaf SLA\"] = corr\n",
    "    else:\n",
    "        corr_table = pd.concat([corr_table, pd.DataFrame({\"Leaf SLA\": corr}, index=[band_name])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson's correlation coefficient (r) between extrapolations and sPlotOpen grids at 0.5 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_table.to_markdown(floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.01 degree grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrapolations\n",
    "pred_001_dir = Path(\"results/predictions/tiled_5x5_deg_MOD09GA.061_ISRIC_soil_WC_BIO_VODCA_0.01_deg_nan-strat=any_thr=0.5\")\n",
    "pred_001_fn = \"merged_predictions.parq\"\n",
    "\n",
    "# GBIF extrapolations (0.01 degree)\n",
    "gbif_N_mass_001 = gpd.read_parquet(pred_001_dir / \"TRYgapfilled_X14_05deg_mean/GBIF\" / pred_001_fn)\n",
    "gbif_N_area_001 = gpd.read_parquet(pred_001_dir / \"TRYgapfilled_X50_05deg_mean_ln/GBIF\" / pred_001_fn)\n",
    "gbif_SLA_001 = gpd.read_parquet(pred_001_dir / \"TRYgapfilled_X11_05deg_mean/GBIF\" / pred_001_fn)\n",
    "\n",
    "# sPlot extrapolations (0.01 degree)\n",
    "sPlot_ext_N_mass_001 = gpd.read_parquet(pred_001_dir / \"TRYgapfilled_X14_05deg_mean/sPlot\" / pred_001_fn)\n",
    "sPlot_ext_N_area_001 = gpd.read_parquet(pred_001_dir / \"TRYgapfilled_X50_05deg_mean_ln/sPlot\" / pred_001_fn)\n",
    "sPlot_ext_SLA_001 = gpd.read_parquet(pred_001_dir / \"TRYgapfilled_X11_05deg_mean/sPlot\" / pred_001_fn)\n",
    "\n",
    "# sPlot maps (0.01 degree)\n",
    "sPlot_N_mass_001 = riox.open_rasterio(\"data/splot/0.01_deg/sPlot_TRYgapfilled_X14_0.01deg.tif\", masked=True)\n",
    "sPlot_N_area_001 = riox.open_rasterio(\"data/splot/0.01_deg/sPlot_TRYgapfilled_X50_0.01deg.tif\", masked=True)\n",
    "sPlot_SLA_001 = riox.open_rasterio(\"data/splot/0.01_deg/sPlot_TRYgapfilled_X11_0.01deg.tif\", masked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back-transform `gbif_N_area` and `sPlot_N_area` as they were trained on log-transformed trait values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back-transform `gbif_N_area` as it was trained on log-transformed trait values\n",
    "gbif_N_area_001[\"GBIF_TRYgapfilled_X50_05deg_mean\"] = np.exp(gbif_N_area_001[\"GBIF_TRYgapfilled_X50_05deg_mean_ln\"])\n",
    "sPlot_ext_N_area_001[\"sPlot_TRYgapfilled_X50_05deg_mean\"] = np.exp(sPlot_ext_N_area_001[\"sPlot_TRYgapfilled_X50_05deg_mean_ln\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_ids = [\"X14\", \"X50\", \"X11\"]\n",
    "trait_names = [\"Leaf N mass\", \"Leaf N area\", \"Leaf SLA\"]\n",
    "splot_trait_names = [\"sPlot_N_mass\", \"sPlot_N_area\", \"sPlot_SLA\"]\n",
    "\n",
    "corr_table = pd.DataFrame(columns=trait_names, index=[\"sPlot\", \"GBIF\"])\n",
    "\n",
    "for trait_id, splot_trait_name, trait_name in zip(\n",
    "    trait_ids, splot_trait_names, trait_names\n",
    "):\n",
    "    for model in [\"GBIF\", \"sPlot\"]:\n",
    "        print(f\"Processing {model} {trait_id}...\")\n",
    "\n",
    "        gdf = read_001_predictions(trait_id, model)\n",
    "        corr = splot_correlation_old(gdf, trait_id, splot_trait_name, \"05_range\")\n",
    "\n",
    "        corr_table.at[model, trait_name] = corr\n",
    "    \n",
    "print(corr_table.to_markdown(floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updated method\n",
    "\n",
    "See `scripts/splot_correlations.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "corr_table = pd.read_parquet(\"results/trait_correlations.parquet\")\n",
    "corr_table.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shrub-Tree-Grass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualize import plot_splot_correlations\n",
    "\n",
    "\n",
    "plot_splot_correlations(corr_table, \"Shrub-Tree-Grass\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
