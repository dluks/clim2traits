{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Train XGBoost Model\n",
    "\n",
    "Author: Daniel Lusk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import spacv\n",
    "import pandas as pd\n",
    "\n",
    "from spacv.visualisation import plot_autocorrelation_ranges\n",
    "from TrainModelConfig import TrainModelConfig\n",
    "from utils.geodata import drop_XY_NAs\n",
    "from utils.visualize import plot_splits\n",
    "from utils.datasets import DataCollection, Dataset, MLCollection, Unit\n",
    "\n",
    "NOTEBOOK = True\n",
    "\n",
    "if NOTEBOOK:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "config = TrainModelConfig()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inat = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.iNat_dir,\n",
    "    collection_name=config.iNat_name,\n",
    "    transform=\"ln\",\n",
    ")\n",
    "\n",
    "wc = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.WC_dir,\n",
    "    collection_name=config.WC_name,\n",
    "    bio_ids=config.WC_bio_ids,\n",
    ")\n",
    "\n",
    "modis = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.MODIS_dir,\n",
    "    collection_name=config.MODIS_name,\n",
    ")\n",
    "\n",
    "soil = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.soil_dir,\n",
    "    collection_name=config.soil_name,\n",
    ")\n",
    "\n",
    "X = DataCollection([wc, modis, soil])\n",
    "Y = DataCollection([inat])\n",
    "\n",
    "# Convert to MLCollection for training\n",
    "XY = MLCollection(X, Y)\n",
    "print(\"XY shape:\", XY.df.shape)\n",
    "\n",
    "XY.drop_NAs(verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "To-Dos:\n",
    "\n",
    "1) ~~Create a data frame where you have all response variables and predictors.~~\n",
    "2) ~~Remove cells where you do not have a value for ANY predictor/response variable (you still may have NA for some columns then).~~\n",
    "3) ~~Train the models and do the evaluation~~\n",
    "4) Repeat step 3, but remove rows where you have at least one NA\n",
    "5) Compare accuracies of step 3 and 4 and see whatÂ´s best.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate autocorrelation range of predictors and generate spatial folds for spatial cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.SAVE_AUTOCORRELATION_RANGES:\n",
    "    coords = XY[\"geometry\"]\n",
    "    data = XY[X.cols]\n",
    "    \n",
    "    _, _, ranges = plot_autocorrelation_ranges(\n",
    "        coords, data, config.LAGS, config.BW, distance_metric=\"haversine\", workers=10\n",
    "    )\n",
    "\n",
    "    np.save(\"ranges.npy\", np.asarray(ranges))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore splits for a single response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.EXPLORE_SPLITS:\n",
    "    y_col = \"iNat_Stem.conduit.density_05deg_ln\"\n",
    "    sample_Xy = XY.df[[\"geometry\", *XY.X.cols, y_col]]\n",
    "\n",
    "    # Drop full-NAs\n",
    "    sample_Xy, sample_X_cols, sample_y_col = drop_XY_NAs(\n",
    "        sample_Xy, XY.X.cols, y_col, True\n",
    "    )\n",
    "\n",
    "    # Sample X data on which split dissimilarity will be measured\n",
    "    sample_data = sample_Xy[sample_X_cols]\n",
    "    sample_locs = sample_Xy[\"geometry\"]\n",
    "\n",
    "    # Grid settings\n",
    "    tile = config.AUTOCORRELATION_RANGE / config.DEGREE\n",
    "    tiles_x = int(np.round(360 / tile))\n",
    "    tiles_y = int(np.round(180 / tile))\n",
    "\n",
    "    # Spatial blocking\n",
    "    hblock = spacv.HBLOCK(\n",
    "        tiles_x,\n",
    "        tiles_y,\n",
    "        shape=\"hex\",\n",
    "        method=\"optimized_random\",\n",
    "        buffer_radius=0.01,\n",
    "        n_groups=10,\n",
    "        data=sample_data,\n",
    "        n_sims=50,\n",
    "        distance_metric=\"haversine\",\n",
    "        random_state=config.RNG_STATE,\n",
    "    )\n",
    "\n",
    "    # Plot splits\n",
    "    print(f\"Tile size: {tile:.2f} degrees\")\n",
    "    plot_splits(hblock, sample_locs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models for each response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.TRAIN_MODE:\n",
    "    XY.train_collection(config.training_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.DEBUG:\n",
    "    from utils.training import block_cv_splits, optimize_params\n",
    "    from os import path\n",
    "    import pathlib\n",
    "    from utils.training import TrainingConfig\n",
    "\n",
    "    results_dir = pathlib.Path(config.RESULTS_DIR, \"test\")\n",
    "    results_csv = pathlib.Path(results_dir, \"training_results.csv\")\n",
    "    train_config = TrainingConfig(\n",
    "        cv_n_groups=2, search_n_trials=2, results_dir=results_dir, results_csv=results_csv\n",
    "    )\n",
    "\n",
    "    y_col = XY.Y.cols[0]\n",
    "\n",
    "    Xy = XY.df[[\"geometry\", *XY.X.cols, y_col]]\n",
    "    Xy, X_cols, y_cols = drop_XY_NAs(Xy, XY.X.cols, y_col, True)\n",
    "\n",
    "    X = Xy[X_cols].to_numpy()\n",
    "    y = Xy[y_col].to_numpy()\n",
    "    coords = Xy[\"geometry\"]\n",
    "\n",
    "    cv = block_cv_splits(\n",
    "        X=X,\n",
    "        coords=coords,\n",
    "        grid_size=train_config.cv_grid_size,\n",
    "        n_groups=train_config.cv_n_groups,\n",
    "        random_state=train_config.random_state,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    reg = optimize_params(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        col_name=y_col,\n",
    "        cv=cv,\n",
    "        save_dir=train_config.results_dir,\n",
    "        n_trials=train_config.search_n_trials,\n",
    "        random_state=train_config.random_state,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
