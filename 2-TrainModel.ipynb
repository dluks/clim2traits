{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Train XGBoost Model\n",
    "\n",
    "Author: Daniel Lusk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacv\n",
    "import pandas as pd\n",
    "\n",
    "from spacv.visualisation import plot_autocorrelation_ranges\n",
    "from TrainModelConfig import TrainModelConfig\n",
    "from utils.geodata import drop_XY_NAs\n",
    "from utils.visualize import plot_splits\n",
    "from utils.datasets import DataCollection, Dataset, MLCollection, CollectionName\n",
    "from utils.dataset_tools import Unit, FileExt\n",
    "from pathlib import Path\n",
    "\n",
    "NOTEBOOK = True\n",
    "\n",
    "if NOTEBOOK:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "config = TrainModelConfig()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inat_orig = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.iNat_dir,\n",
    "    collection_name=config.iNat_name,\n",
    "    transform=\"ln\",\n",
    ")\n",
    "\n",
    "inat_dgvm = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=Path(\"./iNaturalist_traits/maps_iNaturalist/DGVM/continuous_traits/\"),\n",
    "    collection_name=CollectionName.INAT_DGVM,\n",
    "    transform=\"ln\",\n",
    ")\n",
    "\n",
    "inat_gbif = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=Path(\"./iNaturalist_traits/maps_GBIF/traitmaps/TRY_gap_filled/\"),\n",
    "    collection_name=CollectionName.INAT_GBIF,\n",
    "    # filter_outliers=config.training_config.filter_y_outliers,\n",
    ")\n",
    "\n",
    "wc = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.WC_dir,\n",
    "    collection_name=config.WC_name,\n",
    "    bio_ids=config.WC_bio_ids,\n",
    ")\n",
    "\n",
    "modis = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.MODIS_dir,\n",
    "    collection_name=config.MODIS_name,\n",
    ")\n",
    "\n",
    "soil = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.soil_dir,\n",
    "    collection_name=config.soil_name,\n",
    ")\n",
    "\n",
    "vodca = Dataset(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=Path(\"./data/vodca/\"),\n",
    "    collection_name=CollectionName.VODCA,\n",
    "    file_ext=FileExt.NETCDF4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize the datasets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DataCollection([wc, modis, soil, vodca])\n",
    "Y = DataCollection([inat_gbif])\n",
    "\n",
    "# Convert to MLCollection for training\n",
    "XY = MLCollection(X, Y)\n",
    "XY.drop_NAs(verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "To-Dos:\n",
    "\n",
    "1) ~~Create a data frame where you have all response variables and predictors.~~\n",
    "2) ~~Remove cells where you do not have a value for ANY predictor/response variable (you still may have NA for some columns then).~~\n",
    "3) ~~Train the models and do the evaluation~~\n",
    "4) Repeat step 3, but remove rows where you have at least one NA\n",
    "5) Compare accuracies of step 3 and 4 and see whatÂ´s best.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate autocorrelation range of predictors and generate spatial folds for spatial cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.SAVE_AUTOCORRELATION_RANGES:\n",
    "    coords = XY.df[\"geometry\"]\n",
    "    data = XY.df[XY.X.cols]\n",
    "\n",
    "    _, _, ranges = plot_autocorrelation_ranges(\n",
    "        coords, data, config.LAGS, config.BW, distance_metric=\"haversine\", workers=10\n",
    "    )\n",
    "\n",
    "    np.save(\"ranges.npy\", np.asarray(ranges))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore splits for a single response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.EXPLORE_SPLITS:\n",
    "    y_col = \"iNat_Stem.conduit.density_05deg_ln\"\n",
    "    sample_Xy = XY.df[[\"geometry\", *XY.X.cols, y_col]]\n",
    "\n",
    "    # Drop full-NAs\n",
    "    sample_Xy, sample_X_cols, sample_y_col = drop_XY_NAs(\n",
    "        sample_Xy, XY.X.cols, y_col, True\n",
    "    )\n",
    "\n",
    "    # Sample X data on which split dissimilarity will be measured\n",
    "    sample_data = sample_Xy[sample_X_cols]\n",
    "    sample_locs = sample_Xy[\"geometry\"]\n",
    "\n",
    "    # Grid settings\n",
    "    tiles_x = int(np.round(360 / config.AUTOCORRELATION_RANGE))\n",
    "    tiles_y = int(np.round(180 / config.AUTOCORRELATION_RANGE))\n",
    "\n",
    "    # Spatial blocking\n",
    "    hblock = spacv.HBLOCK(\n",
    "        tiles_x,\n",
    "        tiles_y,\n",
    "        shape=\"hex\",\n",
    "        method=\"optimized_random\",\n",
    "        buffer_radius=0.01,\n",
    "        n_groups=10,\n",
    "        data=sample_data,\n",
    "        n_sims=50,\n",
    "        distance_metric=\"haversine\",\n",
    "        random_state=config.RNG_STATE,\n",
    "    )\n",
    "\n",
    "    # Plot splits\n",
    "    print(f\"Tile size: {config.AUTOCORRELATION_RANGE:.2f} degrees\")\n",
    "    plot_splits(hblock, sample_locs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models for each response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### TRAINING  ####################\n",
    "if config.TRAIN_MODE:\n",
    "    config = TrainModelConfig()\n",
    "    XY.train_Y_models(config.training_config, resume=True)\n",
    "##################################################\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.training import train_model_full\n",
    "\n",
    "\n",
    "if config.DEBUG:\n",
    "    from utils.training import block_cv_splits, optimize_params\n",
    "\n",
    "    y_col = XY.Y.cols[0]\n",
    "\n",
    "    Xy = XY.df[[\"geometry\", *XY.X.cols, y_col]]\n",
    "    Xy, X_cols, y_cols = drop_XY_NAs(Xy, XY.X.cols, y_col, True)\n",
    "\n",
    "    X = Xy[X_cols].to_numpy()\n",
    "    y = Xy[y_col].to_numpy()\n",
    "    coords = Xy[\"geometry\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test, coords_train, coords_test = train_test_split(\n",
    "        X, y, coords, test_size=0.2\n",
    "    )\n",
    "\n",
    "    cv = block_cv_splits(\n",
    "        X=X_train,\n",
    "        coords=coords_train,\n",
    "        grid_size=config.training_config.cv_grid_size,\n",
    "        n_groups=config.training_config.cv_n_groups,\n",
    "        random_state=config.training_config.random_state,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    reg = optimize_params(\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        col_name=y_col,\n",
    "        cv=cv,\n",
    "        save_dir=config.training_config.results_dir,\n",
    "        n_trials=config.training_config.search_n_trials,\n",
    "        random_state=config.training_config.random_state,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    model, r2 = train_model_full(\n",
    "        model_params=reg.best_params_,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        verbose=1,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
