{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Train XGBoost Model\n",
    "\n",
    "Author: Daniel Lusk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import spacv\n",
    "import pandas as pd\n",
    "\n",
    "from spacv.visualisation import plot_autocorrelation_ranges\n",
    "from TrainModelConfig import TrainModelConfig\n",
    "from utils.data_retrieval import gdf_from_list\n",
    "from utils.geodata import drop_XY_NAs, merge_gdfs\n",
    "from utils.training import run_training\n",
    "from utils.visualize import plot_splits\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config = TrainModelConfig()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import Dataset, DatasetInfo, FileExt, Unit\n",
    "from utils.datasets import DataCollection\n",
    "\n",
    "inat_info = DatasetInfo(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.iNat_dir,\n",
    "    file_ext=FileExt.TIF,\n",
    "    collection_name=config.iNat_name,\n",
    "    transform=\"ln\",\n",
    ")\n",
    "\n",
    "wc_info = DatasetInfo(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.WC_dir,\n",
    "    file_ext=FileExt.TIF,\n",
    "    collection_name=config.WC_name,\n",
    "    bio_ids=config.WC_bio_ids,\n",
    ")\n",
    "\n",
    "modis_info = DatasetInfo(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.MODIS_dir,\n",
    "    file_ext=FileExt.TIF,\n",
    "    collection_name=config.MODIS_name,\n",
    ")\n",
    "\n",
    "soil_info = DatasetInfo(\n",
    "    res=0.5,\n",
    "    unit=Unit.DEGREE,\n",
    "    parent_dir=config.soil_dir,\n",
    "    file_ext=FileExt.TIF,\n",
    "    collection_name=config.soil_name,\n",
    ")\n",
    "\n",
    "inat = Dataset(info=inat_info)\n",
    "wc = Dataset(info=wc_info)\n",
    "modis = Dataset(info=modis_info)\n",
    "soil = Dataset(info=soil_info)\n",
    "\n",
    "X = DataCollection([wc, modis, soil])\n",
    "Y = DataCollection([inat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import MLCollection\n",
    "\n",
    "\n",
    "XY = MLCollection(X, Y)\n",
    "print(\"XY shape:\", XY.df.shape)\n",
    "\n",
    "XY.drop_NAs(verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "To-Dos:\n",
    "\n",
    "1) ~~Create a data frame where you have all response variables and predictors.~~\n",
    "2) ~~Remove cells where you do not have a value for ANY predictor/response variable (you still may have NA for some columns then).~~\n",
    "3) ~~Train the models and do the evaluation~~\n",
    "4) Repeat step 3, but remove rows where you have at least one NA\n",
    "5) Compare accuracies of step 3 and 4 and see whatÂ´s best.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate autocorrelation range of predictors and generate spatial folds for spatial cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.SAVE_AUTOCORRELATION_RANGES:\n",
    "    coords = XY[\"geometry\"]\n",
    "    data = XY[X.cols]\n",
    "    \n",
    "    _, _, ranges = plot_autocorrelation_ranges(\n",
    "        coords, data, config.LAGS, config.BW, distance_metric=\"haversine\", workers=10\n",
    "    )\n",
    "\n",
    "    np.save(\"ranges.npy\", np.asarray(ranges))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore splits for a single response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"iNat_Stem.conduit.density_05deg_ln\"\n",
    "sample_Xy = XY.df[[\"geometry\", *XY.X.cols, y_col]]\n",
    "\n",
    "# Drop full-NAs\n",
    "sample_Xy, sample_X_cols, sample_y_col = drop_XY_NAs(\n",
    "    sample_Xy, XY.X.cols, y_col, True\n",
    ")\n",
    "\n",
    "# Sample X data on which split dissimilarity will be measured\n",
    "sample_data = sample_Xy[sample_X_cols]\n",
    "sample_locs = sample_Xy[\"geometry\"]\n",
    "\n",
    "# Grid settings\n",
    "tile = config.AUTOCORRELATION_RANGE / config.DEGREE\n",
    "tiles_x = int(np.round(360 / tile))\n",
    "tiles_y = int(np.round(180 / tile))\n",
    "\n",
    "# Spatial blocking\n",
    "hblock = spacv.HBLOCK(\n",
    "    tiles_x,\n",
    "    tiles_y,\n",
    "    shape=\"hex\",\n",
    "    method=\"optimized_random\",\n",
    "    buffer_radius=0.01,\n",
    "    n_groups=10,\n",
    "    data=sample_data,\n",
    "    n_sims=50,\n",
    "    distance_metric=\"haversine\",\n",
    "    random_state=config.RNG_STATE,\n",
    ")\n",
    "\n",
    "# Plot splits\n",
    "print(f\"Tile size: {tile:.2f} degrees\")\n",
    "plot_splits(hblock, sample_locs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models for each response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "param_opt_run_dir = os.path.join(config.PARAM_OPT_RESULTS_DIR, run_time)\n",
    "results_dir = os.path.join(config.MODEL_DIR, run_time)\n",
    "\n",
    "if not os.path.exists(param_opt_run_dir):\n",
    "    os.makedirs(param_opt_run_dir)\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "results_fn = os.path.join(results_dir, f\"{run_time}_results.csv\")\n",
    "data_cols = [\"model\", \"params\", \"mean rmse\", \"std\", \"r-squared\"]\n",
    "results_df = pd.DataFrame(columns=data_cols)\n",
    "\n",
    "for y_col in Y_cols:\n",
    "    print(f\"Processing {y_col}...\\n\")\n",
    "    run_name = f\"{run_time}_{y_col}\"\n",
    "\n",
    "    Xy = XY[[\"geometry\", *X_cols, y_col]]\n",
    "\n",
    "    Xy, X_cols, y_col = drop_NAs(Xy, X_cols, y_col, True)\n",
    "\n",
    "    model_fn, params, rmse, std, r2 = run_training(\n",
    "        Xy=Xy,\n",
    "        X_cols=X_cols,\n",
    "        y_col=y_col,\n",
    "        autocorr_range=config.AUTOCORRELATION_RANGE,\n",
    "        search_n_trials=100,\n",
    "        n_jobs=-1,\n",
    "        random_state=config.RNG_STATE,\n",
    "        param_opt_save_dir=param_opt_run_dir,\n",
    "        final_save_dir=results_dir,\n",
    "        run_name=run_name,\n",
    "    )\n",
    "    results = [model_fn, params, rmse, std, r2]\n",
    "    new_df = pd.DataFrame([results], columns=data_cols)\n",
    "    results_df = pd.concat([results_df, new_df])\n",
    "\n",
    "    results_df.to_csv(os.path.join(config.MODEL_DIR, results_fn))\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
