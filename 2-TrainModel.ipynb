{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Train XGBoost Model\n",
    "\n",
    "Author: Daniel Lusk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from TrainModelConfig import TrainModelConfig\n",
    "from utils.data_retrieval import all_gdfs\n",
    "from utils.visualize import plot_splits\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config = TrainModelConfig()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fns = config.WC_fns + config.MODIS_fns + config.soil_fns\n",
    "Y_fns = config.iNat_fns\n",
    "\n",
    "X = all_gdfs(X_fns)\n",
    "Y = all_gdfs(Y_fns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Preciptation Annual Range by subtracting BIO14 from BIO13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_13 = X.loc[:, [\"bio_13\" in x for x in X.columns]].values\n",
    "bio_14 = X.loc[:, [\"bio_14\" in x for x in X.columns]].values\n",
    "X[\"wc2.1_10m_bio_13-14\"] = bio_13 - bio_14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the unnecessary `x`, `y`, `band` and `spatial_ref` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=[\"x\", \"y\", \"band\", \"spatial_ref\"])\n",
    "Y = Y.drop(columns=[\"x\", \"y\", \"band\", \"spatial_ref\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Dos:\n",
    "\n",
    "1. Match predictors with response variable(s) (just use one variable at first to test all the folllowing steps)\n",
    "2. Remove all-null predictors/response vars\n",
    "3. ~~Standardize the data~~ *Not actually necessary for tree-based models!*\n",
    "4. Divide into spatial CV splits\n",
    "5. Exclude location columns\n",
    "6. Test out training\n",
    "7. Identify optimal hyperparams with grid search + spatial CV\n",
    "8. Repeat training, but remove ANY rows with NA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use just one response variable while developing the methodology. In this case, use specific leaf area (SLA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[[\"geometry\", \"iNat_SLA_05deg_ln\"]]\n",
    "\n",
    "# Drop response variable NAs\n",
    "Y = Y.dropna()\n",
    "\n",
    "Y.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>1. Match predictors with response variable</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[X[\"geometry\"].isin(Y[\"geometry\"])]\n",
    "print_shapes(X, Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>2. Remove all-NA predictors and match response variable with new predictors</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna(subset=X.columns.difference([\"geometry\"]), how=\"all\")\n",
    "print_shapes(X, Y)\n",
    "\n",
    "Y = Y.loc[Y[\"geometry\"].isin(X[\"geometry\"])]\n",
    "print_shapes(X, Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>3. Standardize the data by centering to the mean and scaling to the STD (skipped because not actually necessary for tree-based models)</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>4. Divide into geographic splits for spatial K-fold cross-validation</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Generate variograms to determine block size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skgstat as skg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XYs = X[\"geometry\"]\n",
    "coords = np.asarray(list(map(lambda x : (x.x, x.y), XYs)))\n",
    "values = X[\"wc2.1_0.5_deg_bio_1\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = coords[~np.isnan(values)]\n",
    "values = values[~np.isnan(values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = skg.Variogram(coordinates=coords, values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacv\n",
    "from spacv.visualisation import plot_autocorrelation_ranges\n",
    "import numpy as np\n",
    "\n",
    "# df = gpd.read_file('/opt/conda/lib/python3.7/site-packages/libpysal/examples/baltim/baltim.shp')\n",
    "\n",
    "# XYs = df['geometry']\n",
    "# cols = ['NROOM', 'PRICE', 'AGE', 'SQFT']\n",
    "# X = df[cols]\n",
    "# y = df['PATIO']\n",
    "\n",
    "XYs = X[\"geometry\"]\n",
    "x = X[[\"wc2.1_0.5_deg_bio_1\"]]\n",
    "\n",
    "# xys = XYs.iloc[~np.isnan(x).values]\n",
    "# x = x[~np.isnan(x).values]\n",
    "\n",
    "lags = np.arange(0, 400, 50)\n",
    "bw = 5\n",
    "\n",
    "plot_autocorrelation_ranges(XYs, X[X.columns.difference([\"geometry\"])], lags, bw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import spacv\n",
    "\n",
    "XYs = X[\"geometry\"]\n",
    "skcv = spacv.SKCV(n_splits=10, buffer_radius=10)\n",
    "\n",
    "plot_splits(skcv, XYs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacv.grid_builder import construct_blocks\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "construct_blocks(X, method='random', tiles_x=10, tiles_y=10, n_groups=3).plot(column='grid_id', ax=ax, edgecolor='black', cmap='viridis')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop NaNs from labels and convert dataframes to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X.to_numpy()\n",
    "Y_np = Y.dropna().to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test and convert data into DMatrices for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_np, Y_np, test_size=2.0)\n",
    "\n",
    "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
